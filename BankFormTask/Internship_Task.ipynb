{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Task: Extract Handwritten data from a Bank form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been given a 2 page long form that a user has to fill, we need to extract this data and convert this into text using\n",
    "HTR tehcniques. The following notebook uses a series of steps that have been undertaken for the same.\n",
    "\n",
    "1 Convert 2 page pdf to images.\n",
    "\n",
    "2 Warp each image to bring the input images to standard format.\n",
    "\n",
    "3 Make a mask that contains all the ROI, Build a script to get the coordinates.\n",
    "4 Place the mask over the image and extract ROIs (Done)\n",
    "\n",
    "5 For each ROI split the image into constituent characters. \n",
    "\n",
    "6 Build a Text Classifier using a dataset\n",
    "\n",
    "7 Preprocess and Train the CNN.\n",
    "\n",
    "8 Build a function that takes input and returns the text data\n",
    "\n",
    "(Note: for now we assume the image is scanned and hence warping can be skipped, shall be taken up later\n",
    "PDF to Image library is complex to load on windows machine, hence will be taken up in google colab later onn.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the basic libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgInput = cv2.imread('form-2.jpg')\n",
    "imgshow = imgInput.copy()\n",
    "img = cv2.imread('page1.jpeg',0)\n",
    "query = cv2.imread('form-1.jpg',0)\n",
    "mdl = load_model('htr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w, _ = imgInput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring variables to be used\n",
    "cnt , p1 , p2 , checkroi , num , textroi , dateroi  = 0 , [] , [] , [] , 0 , [] , []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ROI regions from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to get ROIs\n",
    "# Here we have divided each image into 2 parts and taking manual roi one after the other\n",
    "# Long Long Task\n",
    "def click_event(event, x, y, flags, params): \n",
    "        global cnt,p1,p2,textroi,num,checkroi,dateroi\n",
    "        if event == cv2.EVENT_LBUTTONDOWN: \n",
    "            if cnt ==0:\n",
    "                p1 = [x*2,(y)*2]\n",
    "                cnt += 1\n",
    "                cv2.imshow('image', img[:600,:]) \n",
    "            else:\n",
    "                p2 = [x*2,(y)*2]\n",
    "                cnt -= 1\n",
    "                name = input(\"Enter Name: \")\n",
    "                dtp = input(\"Enter Type: \")\n",
    "                if dtp=='check':\n",
    "                    checkroi.append([p1,p2,name])\n",
    "                elif dtp== 'text':\n",
    "                    num =int(input('No. of Boxes: '))\n",
    "                    textroi.append([p1,p2,name,num])\n",
    "                elif dtp == 'date':\n",
    "                    dateroi.append([p1,p2,name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Name: Bangladesh\n",
      "Enter Type: check\n",
      "Enter Name: Bhutan\n",
      "Enter Type: check\n",
      "Enter Name: Maldives\n",
      "Enter Type: check\n",
      "Enter Name: Nepal\n",
      "Enter Type: check\n",
      "Enter Name: PK\n",
      "Enter Type: check\n",
      "Enter Name: Sri Lanka\n",
      "Enter Type: check\n",
      "Enter Name: AAIM\n",
      "Enter Type: check\n",
      "Enter Name: Anti Theft\n",
      "Enter Type: check\n",
      "Enter Name: Limit TTP\n",
      "Enter Type: check\n",
      "Enter Name: Diff Abled Design\n",
      "Enter Type: check\n",
      "Enter Name: Usage Restric\n",
      "Enter Type: check\n",
      "Enter Name: AAIM No.\n",
      "Enter Type: text\n",
      "No. of Boxes: 17\n",
      "Enter Name: Expiry Dt\n",
      "Enter Type: date\n",
      "Enter Name: F. Embassy\n",
      "Enter Type: check\n",
      "Enter Name: Racing\n",
      "Enter Type: check\n",
      "Enter Name: Driving Tution\n",
      "Enter Type: check\n",
      "Enter Name: Vintage Car\n",
      "Enter Type: check\n",
      "Enter Name: Fibre Glass Tank\n",
      "Enter Type: check\n",
      "Enter Name: Loss Cover\n",
      "Enter Type: check\n",
      "Enter Name: Imp w/o Custom duty\n",
      "Enter Type: check\n",
      "Enter Name: Payment Adv\n",
      "Enter Type: check\n",
      "Enter Name: Vehicle Insp\n",
      "Enter Type: check\n",
      "Enter Name: Ren Notice\n",
      "Enter Type: check\n",
      "Enter Name: Sale Deed\n",
      "Enter Type: check\n",
      "Enter Name: NCB Res Letter\n",
      "Enter Type: check\n",
      "Enter Name: List of Acc\n",
      "Enter Type: check\n",
      "Enter Name: RC Book\n",
      "Enter Type: check\n",
      "Enter Name: c\n",
      "Enter Type: c\n",
      "Enter Name: Val Certi\n",
      "Enter Type: check\n",
      "Enter Name: c\n",
      "Enter Type: c\n",
      "Enter Name: Driving Licence\n",
      "Enter Type: check\n",
      "Enter Name: PAN \n",
      "Enter Type: check\n",
      "Enter Name: c\n",
      "Enter Type: c\n",
      "Enter Name: Tel Bill\n",
      "Enter Type: check\n",
      "Enter Name: Passport\n",
      "Enter Type: check\n",
      "Enter Name: Ration Card\n",
      "Enter Type: check\n",
      "Enter Name: Govt ID\n",
      "Enter Type: check\n",
      "Enter Name: Driving License\n",
      "Enter Type: check\n",
      "Enter Name: Voter Card\n",
      "Enter Type: check\n",
      "Enter Name: Elec Bill\n",
      "Enter Type: check\n",
      "Enter Name: c\n",
      "Enter Type: c\n",
      "Enter Name: Aadhar\n",
      "Enter Type: check\n",
      "Enter Name: Physical\n",
      "Enter Type: check\n",
      "Enter Name: e FORMAT\n",
      "Enter Type: check\n",
      "Enter Name: NSDL DBMS\n",
      "Enter Type: check\n",
      "Enter Name: CDSL\n",
      "Enter Type: check\n",
      "Enter Name: Karvy\n",
      "Enter Type: check\n",
      "Enter Name: CAMS\n",
      "Enter Type: check\n",
      "Enter Name: have e insurance\n",
      "Enter Type: check\n",
      "Enter Name: Insurance No.\n",
      "Enter Type: text\n",
      "No. of Boxes: 13\n",
      "Enter Name: CKYC\n",
      "Enter Type: text\n",
      "No. of Boxes: 13\n",
      "Enter Name: Cheque\n",
      "Enter Type: check\n",
      "Enter Name: DD\n",
      "Enter Type: check\n",
      "Enter Name: Cash\n",
      "Enter Type: check\n",
      "Enter Name: EFT\n",
      "Enter Type: check\n",
      "Enter Name: Debit/Credit Card\n",
      "Enter Type: check\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('form-2.jpg', 1) \n",
    "img = cv2.resize(img,(w//2,h//2))\n",
    "    \n",
    "while(1):\n",
    "    # displaying the image \n",
    "    cv2.imshow('image', img[:600,:]) \n",
    "    # and calling the click_event() function \n",
    "    cv2.setMouseCallback('image', click_event) \n",
    "    \n",
    "    # wait for a key to be pressed to exit \n",
    "    if cv2.waitKey(1) & 0xFF == ord('z') :\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For bounding boxes there are 2 categories, the one with bounding boxes and the other with blanks\n",
    " For the ones with bounding boexs we need to resize the image to 28x28*n where n is the number of boxes\n",
    " For the ones with fields we will have to employ histogram splitting method which will be done in the next stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('page1.jpeg',0)    # Page1 of form, change page for next page\n",
    "query = cv2.imread('form-1.jpg',0)   # Scanned page1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Warping\n",
    "orb = cv2.ORB_create(10000)\n",
    "kp1, des1 = orb.detectAndCompute(query,None)\n",
    "#imkp = cv2.drawKeypoints(query,kp1,None) # if one wants to see the points detected\n",
    "#cv2.imshow('',imgmt)\n",
    "#cv2.waitKey(0)\n",
    "kp2, des2 = orb.detectAndCompute(img,None)\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "matches = bf.match(des2,des1)\n",
    "matches.sort(key=lambda x:x.distance)\n",
    "good = matches[:1000]\n",
    "imgmt = cv2.drawMatches(img,kp2,query,kp1,good,None,flags=2)\n",
    "srcpt = np.float32([kp2[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "dstpt = np.float32([kp1[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "M , _ = cv2.findHomography(srcpt,dstpt,cv2.RANSAC,5.0)\n",
    "imgsc = cv2.warpPerspective(img,M,(1654,2339))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell that takes in text roi and outputs the OCRed data\n",
    "def text_data(listed):\n",
    "    dct = {} # Dictionary to contain all fields\n",
    "    for row in listed:\n",
    "        # Slicing\n",
    "        roi = imgsc[row[0][1]:row[1][1],row[0][0]:row[1][0]]\n",
    "        n = row[3]  # to get data from dates, skip these lines and replace n with 7 \n",
    "        if(n==0):\n",
    "            continue\n",
    "        roi = cv2.resize(roi,(28*n,28)) \n",
    "        i = 0\n",
    "        field = []\n",
    "        while(i<28*8):\n",
    "            sliced = roi[:,i:i+28] # splitting into each box\n",
    "            _, sliced  = cv2.threshold(sliced, 80, 255, cv2.THRESH_BINARY) \n",
    "            if(np.sum(sliced)<10000):    # To introduce space if there is no character\n",
    "                field.append(' ')\n",
    "            else:\n",
    "                field.append(get_char(sliced)) # get_char will be the function which will fetch the \n",
    "            # predicted value from the CNN\n",
    "            i += 28   \n",
    "        cv2.waitKey(0)\n",
    "        dct[row[2]] = ''.join(field)\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For text data that does not have boxes\n",
    "def nobox_data(listed):\n",
    "    for row in listed:\n",
    "        if row[3]!=0:\n",
    "            continue\n",
    "        dct = {}\n",
    "        img = imgsc[row[0][1]:row[1][1],row[0][0]:row[1][0]]\n",
    "        img = np.asarray(cv2.bitwise_not(img))\n",
    "        img = img//255\n",
    "        arr = [0 for i in range(img.shape[1])]\n",
    "        for i in range(img.shape[0]):\n",
    "            for j in range(img.shape[1]):\n",
    "                arr[j] += img[i][j]\n",
    "        count = 0\n",
    "        for i in range(0,len(arr)):\n",
    "            if(arr[i]==0):\n",
    "                count += 1\n",
    "            if(arr[i]!=0 and count>=5):\n",
    "                print(i-count,' - ',i)\n",
    "                count = 0\n",
    "        # Start of split\n",
    "        for idx,el in enumerate(arr):\n",
    "            if el >= 5:\n",
    "                print(idx)\n",
    "                break\n",
    "        idx -= 10\n",
    "        split = []\n",
    "        count = 0\n",
    "        # Find split of 5 pixels or more\n",
    "        for i in range(idx,len(arr)):\n",
    "            if(arr[i]<=2):\n",
    "                count += 1\n",
    "            elif(arr[i]>0 and count>=1):\n",
    "                split.append((idx,i-(count//2)))\n",
    "                count = 0\n",
    "                idx = i\n",
    "        l = []\n",
    "        for idx,el in enumerate(split[1:]):\n",
    "            img = verticleadjust(er[:,el[0]:el[1]])\n",
    "            l.append(predict(verticleadjust(er[:,el[1]:])))\n",
    "        dct[row[2]] = ''.join(l)\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertically trimming the image\n",
    "def verticleadjust(im):\n",
    "    # Start of split\n",
    "    img = np.asarray(cv2.bitwise_not(im))\n",
    "    img = img//255\n",
    "    ar2 = [0 for i in range(img.shape[0])]\n",
    "    for j in range(img.shape[1]):\n",
    "        for i in range(img.shape[0]):\n",
    "            ar2[i] += img[i][j]\n",
    "    \n",
    "    for idx,el in enumerate(ar2):\n",
    "        if el >= 5:\n",
    "            break\n",
    "    idx -= 10\n",
    "    end = len(ar2)-1\n",
    "    for i,el in enumerate(ar2):\n",
    "        if el >= 5:\n",
    "            end = i\n",
    "    end += 10\n",
    "    return cv2.resize(im[idx:end,:],(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in date roi and gives output \n",
    "# Cell that takes in text roi and outputs the OCRed data\n",
    "def date_data(listed):\n",
    "    dct = {} # Dictionary to contain all fields\n",
    "    for row in listed:\n",
    "        # Slicing\n",
    "        roi = imgsc[row[0][1]:row[1][1],row[0][0]:row[1][0]]\n",
    "        roi = cv2.resize(roi,(28*8,28)) \n",
    "        i = 0\n",
    "        field = []\n",
    "        while(i<28*8):\n",
    "            sliced = roi[:,i:i+28] # splitting into each box\n",
    "            _, sliced  = cv2.threshold(sliced, 80, 255, cv2.THRESH_BINARY) \n",
    "            field.append(get_num(sliced)) # get_char will be the function which will fetch the \n",
    "            # predicted value from the CNN\n",
    "            i += 28   \n",
    "        cv2.waitKey(0)\n",
    "        dct[row[2]] = str(field[0:2])+'/'+str(field[2:4])+'/'+str(field[4:])\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in checkbox data and returns list of checkboxes that were ticked\n",
    "def checkdata(lst):\n",
    "    ticked = []\n",
    "    for d in lst:\n",
    "        img = imgsc[d[0][1]:d[1][1],d[0][0]:d[1][0]]\n",
    "        _, th = cv2.threshold(img, 100, 255, cv2.THRESH_BINARY) \n",
    "        inv = cv2.bitwise_not(th)\n",
    "        s = np.sum(inv)\n",
    "        if(s>25000):\n",
    "            ticked.append(d[2])\n",
    "    return ticked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get char function\n",
    "# Takes in the slice, gets prediction from result and matches it with column correctly\n",
    "labels = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'J', 11: 'K', \n",
    "          12: 'l', 13: 'S', 14: 'T', 15: 'U', 16: 'V', 17: 'W', 18: 'X', 19: 'Y', 20: 'a', 21: 'A', 22: 'b',\n",
    "          23: 'B', 24: 'c', 25: 'd', 26: 'D',  27: 'e', 28: 'E', 29: 'f', 30: 'g', 31: 'G', 32: 'h',\n",
    "          33: 'H',  34: 'i', 35: 'L', 36: 'm', 37: 'n', 38: 'N', 39: 'o', 40: 'p', 41: 'q', 42: 'Q', \n",
    "          43: 'r', 44: 'R', 45: 'T', 46: 'z'}\n",
    "\n",
    "def get_char(img):\n",
    "    img = img/255.0\n",
    "    img = img[2:-2,2:-2]\n",
    "    img = img.resize(img,(28,28))\n",
    "    img = np.reshape(img,(-1,28,28,1))\n",
    "    pred = mdl.predict(img)\n",
    "    idx = pred.argmax(axis=-1)\n",
    "    return labels[idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in date data and predicts the date\n",
    "def get_num(img):\n",
    "    img = img/255.0\n",
    "    img = img[2:-2,2:-2]\n",
    "    img = img.resize(img,(28,28))\n",
    "    img = np.reshape(img,(-1,28,28,1))\n",
    "    pred = mnist.predict(img)\n",
    "    idx = pred.argmax(axis=-1)\n",
    "    return idx[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The roi data has been stored in the text file, it contains\n",
    "date1,date2,check1,check2,text1,text2\n",
    "where date, check and text correspond to the type and 1 and 2 are the page numbers\n",
    "the lists are to be copied according to need and send to the functions as mentioned in the name.\n",
    "This has been done to avoid confusion and redundant cells in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_data(text1) # or text2\n",
    "text_wo_box = nobox_data(text1) # or text2\n",
    "dates = date_data(date1) # or date2\n",
    "checkboxes = check_data(check1) # or check2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pls. Note- OCR for test without data is being perfected, and due to scanner issues photo was clicked from mobile with introduced substantial noise which caused accuracy to dip, for scanned images the code shall work well. \n",
    "Due to upcoming end sem exams, I could not give more time, apologies for that.\n",
    "Thankyou"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
